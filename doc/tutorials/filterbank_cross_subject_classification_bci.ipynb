{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a filterbank model with alignment\n",
    "\n",
    "This notebook is based on the [MNE example](https://mne.tools/dev/auto_examples/decoding/decoding_csp_eeg.html) and illustrates the construction of the filterbank models including alignment steps. Here, we perform cross-subject classification.\n",
    "\n",
    "First we load the data of two subjects from the EEGBCI dataset: one for train, that we refer as the source subject, and one for test, the target subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "from coffeine import compute_coffeine, make_filter_bank_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('critical')\n",
    "pd.set_option(\"large_repr\", \"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -1.0, 4.0\n",
    "event_id = dict(hands=2, feet=3)\n",
    "subject_source = 1\n",
    "subject_target = 5\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "raw_fnames_source = eegbci.load_data(subject_source, runs)\n",
    "raw_fnames_target = eegbci.load_data(subject_target, runs)\n",
    "raw_source = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames_source])\n",
    "raw_target = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames_target])\n",
    "eegbci.standardize(raw_source)  # set channel names\n",
    "eegbci.standardize(raw_target)  # set channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply band-pass filter\n",
    "raw_source.filter(4.0, 35.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "raw_target.filter(4.0, 35.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "events_source, _ = events_from_annotations(raw_source, event_id=dict(T1=2, T2=3))\n",
    "events_target, _ = events_from_annotations(raw_target, event_id=dict(T1=2, T2=3))\n",
    "picks_source = pick_types(raw_source.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "picks_target = pick_types(raw_target.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epochs_source = Epochs(\n",
    "    raw_source,\n",
    "    events_source,\n",
    "    event_id,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    proj=True,\n",
    "    picks=picks_source,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "epochs_target = Epochs(\n",
    "    raw_target,\n",
    "    events_target,\n",
    "    event_id,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    proj=True,\n",
    "    picks=picks_target,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "labels_source = epochs_source.events[:, -1] - 2\n",
    "labels_target = epochs_target.events[:, -1] - 2\n",
    "conditions = ['feet', 'hand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building seperate coffeine dataframes for source and target data\n",
    "\n",
    "Covariances are computed on pre-defined frequency bands for each subject and dataframes are created with columns corresponding to the frequency bands. The elements of the dataframes are the covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
       "RangeIndex: 5 entries, 0 to 4\n",
       "Data columns (total 2 columns):\n",
       " #   Column  Non-Null Count  Dtype \n",
       "---  ------  --------------  ----- \n",
       " 0   alpha1  5 non-null      object\n",
       " 1   alpha2  5 non-null      object\n",
       "dtypes: object(2)\n",
       "memory usage: 212.0+ bytes\n",
       "</pre>"
      ],
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 5 entries, 0 to 4\n",
       "Data columns (total 2 columns):\n",
       " #   Column  Non-Null Count  Dtype \n",
       "---  ------  --------------  ----- \n",
       " 0   alpha1  5 non-null      object\n",
       " 1   alpha2  5 non-null      object\n",
       "dtypes: object(2)\n",
       "memory usage: 212.0+ bytes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_source, feature_info_source = compute_coffeine(epochs_source, frequencies=('ipeg', ['alpha1', 'alpha2']))\n",
    "X_df_target, feature_info_target = compute_coffeine(epochs_target, frequencies=('ipeg', ['alpha1', 'alpha2']))\n",
    "X_df_source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classification accuracy with and without alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first construct a model without alignment steps as done in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_model = make_filter_bank_classifier(\n",
    "    names=list(X_df_source.columns),\n",
    "    method='riemann',\n",
    "    projection_params=dict(scale=1, n_compo=60, reg=0),\n",
    "    estimator=LogisticRegression(solver='liblinear', C=1e7)\n",
    ")\n",
    "fb_model.fit(X_df_source, labels_source)\n",
    "score = fb_model.score(X_df_target, labels_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_model = make_filter_bank_classifier(\n",
    "    names=list(X_df_source.columns),\n",
    "    method='riemann',\n",
    "    alignment=['re-center', 're-scale'],\n",
    "    # domains=['source']*X_df_source.shape[0],\n",
    "    projection_params=dict(scale=1, n_compo=60, reg=0),\n",
    "    estimator=LogisticRegression(solver='liblinear', C=1e7)\n",
    ")\n",
    "fb_model.fit(X_df_source, labels_source, domains=['source']*X_df_source.shape[0])\n",
    "score = fb_model.score(X_df_target, labels_target, domains=['target_domain']*X_df_target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222222222222222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(10, test_size=0.8, random_state=42)\n",
    "scores = []\n",
    "for train_index, test_index in cv.split(X_df_target):\n",
    "    X_df_target_train = X_df_target.iloc[train_index]\n",
    "    labels_target_train = labels_target[train_index]\n",
    "    X_df_target_test = X_df_target.iloc[test_index]\n",
    "    labels_target_test = labels_target[test_index]\n",
    "    X_df_train = pd.concat([X_df_source, X_df_target_train])\n",
    "    y_train = np.concatenate([labels_source, labels_target_train])\n",
    "    domains = ['source']*X_df_source.shape[0] + ['target_domain']*X_df_target_train.shape[0]\n",
    "    fb_model.fit(X_df_train, y_train, domains=domains)\n",
    "    scores.append(fb_model.score(X_df_target_test, labels_target_test,\n",
    "                                 domains=['target_domain']*X_df_target_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean classification accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean classification accuracy: {np.mean(scores):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75,\n",
       " 0.5833333333333334,\n",
       " 0.6388888888888888,\n",
       " 0.6666666666666666,\n",
       " 0.4722222222222222,\n",
       " 0.5833333333333334,\n",
       " 0.6388888888888888,\n",
       " 0.6111111111111112,\n",
       " 0.5,\n",
       " 0.6944444444444444]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dameeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
